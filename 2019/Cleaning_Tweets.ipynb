{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72 <br>AND Annie's \"Text Normalization Demo.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        32000\n",
       "Sentiment    32000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havin relaxin nite, drinkin earl grey &amp;amp; wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atif089 cool that would be nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... i HATE lyn-z... sorry i just had to say it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is awake, bored, and annoyed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song of the day  http://tinyurl.com/cpkjrm lac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  havin relaxin nite, drinkin earl grey &amp; wa...          4\n",
       "1                  @atif089 cool that would be nice           4\n",
       "2  ... i HATE lyn-z... sorry i just had to say it...          0\n",
       "3                      is awake, bored, and annoyed           0\n",
       "4  song of the day  http://tinyurl.com/cpkjrm lac...          4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5) # \"4\" represents \"positive\", \"0\" represents \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isPlayer Has Died! Sorry</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So bored</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My friends made me join twitter.. so here i am  hows everyones day so far?</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Morning</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet  Sentiment\n",
       "isPlayer Has Died! Sorry                              6.0        NaN\n",
       "Good morning                                          5.0        NaN\n",
       "So bored                                              3.0        NaN\n",
       "My friends made me join twitter.. so here i am ...    3.0        NaN\n",
       "Good Morning                                          3.0        NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(pd.value_counts).head() # Check and count all duplicated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        32000\n",
       "Sentiment    32000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # Reduce tweets from 32000 to 31944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        32000\n",
       "Sentiment    32000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = df\n",
    "training_df.count() # Reduce tweets from 31944 to 31938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# python -m spacy download en\n",
    "\n",
    "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df1=training_df #Create training_df['Tweet']1 as a back-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowercase the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['Tweet']=training_df['Tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey &amp; wa...\n",
       "1                    @atif089 cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5    @prettyhoneydip iight lol ; i got u when i tal...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7    @jessicagottlieb  prime example why it doesn't...\n",
       "8                        @bettie_mcfly you know, why? \n",
       "9    @mcrmuffin d i got your update on my phone!! y...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove @Word and \"#Word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTags(s):\n",
    "    s = re.sub(\"@[a-zA-Z0-9_]+\",\" \", s) #remove the @<the word>\n",
    "    #s = re.sub(\"#[a-zA-Z0-9_]+\",\" \", s) #remove the #<the word>\n",
    "    \n",
    "    return s\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeTags)\n",
    "training_df['Tweet'] = training_df['Tweet'].str.replace('#','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey &amp; wa...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing HTML and HTTP Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(strip_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removewebsite(http):\n",
    "    http = re.sub(r\"http\\S+\", \"\", http) #remove the http://<the word>\n",
    "    www =  re.sub(r'www.[^ ]+', \"\", http)\n",
    "    return www\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removewebsite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_accented_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6             thinks she has run up a a300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i am soooo board '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)\n",
    "training_df[\"Tweet\"][1160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Single Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_single_letters(text):\n",
    "    #re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    words = [x for x  in tokenizer.tokenize(letters_only) if len(x) > 1]\n",
    "    \n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "training_df['Tweet'] = training_df['Tweet'].apply(remove_single_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert spaces between special characters to isolate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertspace(inspace):\n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    inspace = special_char_pattern.sub(\" \\\\1 \", inspace)\n",
    "    return inspace\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(insertspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNumbers(n):\n",
    "    n = re.sub(\"1[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"2[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"3[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"4[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"5[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"6[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"7[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"8[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"9[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"[0-9]\",\" \", n) \n",
    "    return n\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeNumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    text = re.sub('[^a-zA-Z0-9\\s+]', '', text)\n",
    "    text = re.sub('[+]', '', text)\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite drinkin earl grey watchin v...\n",
       "1                              cool that would be nice\n",
       "2                    hate lyn sorry just had to say it\n",
       "3                           is awake bored and annoyed\n",
       "4                       song of the day laceys awesome\n",
       "5              iight lol got when talk him im not home\n",
       "6                     thinks she has run up phone bill\n",
       "7    prime example why it does not really pay to au...\n",
       "8                                         you know why\n",
       "9      got your update on my phone yus wats matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    have relaxin nite drinkin earl grey watchin ve...\n",
       "1                              cool that would be nice\n",
       "2                   hate lyn sorry just have to say it\n",
       "3                           be awake bored and annoyed\n",
       "4                        song of the day lacey awesome\n",
       "5            iight lol get when talk him i be not home\n",
       "6                     think she have run up phone bill\n",
       "7    prime example why it do not really pay to auto...\n",
       "8                                         you know why\n",
       "9       get your update on my phone yus wat matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    relaxin nite drinkin earl grey watchin cool sh...\n",
       "1                                      cool would nice\n",
       "2                                   hate lyn sorry say\n",
       "3                                  awake bored annoyed\n",
       "4                               song day lacey awesome\n",
       "5                          iight lol get talk not home\n",
       "6                                 think run phone bill\n",
       "7    prime example not really pay auto follow irres...\n",
       "8                                                 know\n",
       "9                  get update phone yus wat matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeline(line):\n",
    "    line = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',line)\n",
    "    return line\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removewhite(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removewhite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem import PorterStemmer\n",
    "#ps = PorterStemmer()\n",
    "#for word in nlp(training_df['Tweet'][1]):\n",
    "    #print(word)\n",
    "    \n",
    "#def stem_text(text):\n",
    "    #tokens = tokenizer.tokenize(text)\n",
    " \n",
    "    #stem_tokens = [ps.stem(token) for token in tokens]\n",
    "    #filtered_text = ' '.join(stem_tokens)    \n",
    "    #return filtered_text\n",
    "\n",
    "\n",
    "#training_df['Tweet']=training_df['Tweet'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        False\n",
       "Sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_csv('training_cleaned.csv',encoding='utf-8',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
