{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72 <br>AND Annie's \"Text Normalization Demo.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        32000\n",
       "Sentiment    32000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havin relaxin nite, drinkin earl grey &amp;amp; wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atif089 cool that would be nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... i HATE lyn-z... sorry i just had to say it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is awake, bored, and annoyed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song of the day  http://tinyurl.com/cpkjrm lac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  havin relaxin nite, drinkin earl grey &amp; wa...          4\n",
       "1                  @atif089 cool that would be nice           4\n",
       "2  ... i HATE lyn-z... sorry i just had to say it...          0\n",
       "3                      is awake, bored, and annoyed           0\n",
       "4  song of the day  http://tinyurl.com/cpkjrm lac...          4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head(5) # \"4\" represents \"positive\", \"0\" represents \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isPlayer Has Died! Sorry</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Morning</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So bored</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back to work</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@workformeonline I didn't understand that   Try commands like 'Buy 30 #tag' or 'Sell 30 #tag'</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My tummy hurts</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My friends made me join twitter.. so here i am  hows everyones day so far?</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headache</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not feeling so good</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thunderstorm</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Going out</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@heidimontag Ur Are The Most Stunning Girl On This Planet &amp;amp; I Love You! &amp;lt;3  Its Skye By The Way From Australia I Called You Yesterday</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not to worry, noone got that one. Next question starts in 1 minute, get your thinking caps on</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off to work</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cant afford to see Angels and Demons, so i watched it for free: http://tr.im/lvBu</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>getting ready for work</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am so so so so so bored of studying</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back from lunch</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So tired</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I think I'm getting sick</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I cant sleep</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is doing homework</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with you. Your jst gonna make me sadder if you go</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok I REALLY need to go to bed and stop playing around with Twitter adding new friends!! Hello all you new people</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is seriously freakin out over next week!!!!!!! cant wait till friday  n Im FREE!!!!!! oh dear ive got a dance exam 2 worry about 2!  xxx</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is poorly sick</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has learned a new juggle(/bounce?) for christie  yeyee.. 5 wins nadagdag sakin and 2 loss  http://plurk.com/p/z2fhe</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ddlovato AJ RAFAEL (AWESOME MUSICIAN, FAMOUS ON YOUTUBE) COVERED YOUR SONG, DON'T FORGET. PLEASE WATCH IT  IT'S GOOD! http://bit.ly/vFWAs</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning world!</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Life is too short..</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so happy to be back in prison</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed his train as the geniuses at the station didn't tell anyone it had changed platform</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oh no! look at the time! It's time for me to be asleep so I can go to the place where I spend all my time!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://twitpic.com/6fwfw - Rip-My brothers Hair...Sad day</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@lazylightning1 LOL! Didn't settle. It is a paddle group, and unlike Syncra, is portable, 110V  It'll pair nice with the Speedster!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is up feeding Kaylee</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such a bad headache. wheres katie?  tell her i'm stuck in tallatrashy without her. h8 maiiii lyf3.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Rocmoney I knowww</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its rained for a full week</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am trying to figure out m.slandr.net... Twitter Mobile does not work on my phone (bummer)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's rainy, yeah</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watching Matilda</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Deejaywilliams Pic for me didn't work.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@IAMtheCOMMODORE andrew, you need to get a blog   haha i love you</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@xTerlasifiQue Ahaha, thanks!  It's on Wednesday though. &amp;lt;3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I met her, but I didn't get a picture  but i did get a high five</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Our God Country To DEFEND - In tthaaaaaaaaaa &amp;quot;AIR FORCE&amp;quot;  http://bit.ly/ARayu   LOOK UP Moooooooo</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my blackberry is being lame. no twitpics  I just finished lunch now off to see my lady Suzy.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@lautner_taylor i love you sooooooo much!! y r u playin jake</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i hate sky+ for not filming all of princess protection program. what a bitch!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello my 1,000th tweet</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working  looking forward to weekend.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH MY GGGOD,SO BORINGG THATS IT WATCHING STUPIDS THINGS. HAHAHAHAHAHA  .&amp;quot;</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@DCMA_Collective a speaker at my church yesterday was wearing a DCMA hoodie.. thought that was cool</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Just got back to grammys. Mums on her way to England and Dillon is on his way home  miss them both.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@elainechan98 hahaha my parents éº»éº»åœ°æ¬£è³ž my cookings... coz i only know how to cook è¥¿å¼?é‡Ž</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@katekinners YES! I really thank you for the link!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15990.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet  Sentiment\n",
       "isPlayer Has Died! Sorry                              6.0        NaN\n",
       "Good morning                                          5.0        NaN\n",
       "Good Morning                                          3.0        NaN\n",
       "So bored                                              3.0        NaN\n",
       "back to work                                          3.0        NaN\n",
       "@workformeonline I didn't understand that   Try...    3.0        NaN\n",
       "My tummy hurts                                        3.0        NaN\n",
       "My friends made me join twitter.. so here i am ...    3.0        NaN\n",
       "Headache                                              2.0        NaN\n",
       "Not feeling so good                                   2.0        NaN\n",
       "thunderstorm                                          2.0        NaN\n",
       "Going out                                             2.0        NaN\n",
       "@heidimontag Ur Are The Most Stunning Girl On T...    2.0        NaN\n",
       "Not to worry, noone got that one. Next question...    2.0        NaN\n",
       "off to work                                           2.0        NaN\n",
       " cant afford to see Angels and Demons, so i wat...    2.0        NaN\n",
       "getting ready for work                                2.0        NaN\n",
       "I am so so so so so bored of studying                 2.0        NaN\n",
       "back from lunch                                       2.0        NaN\n",
       "So tired                                              2.0        NaN\n",
       "I think I'm getting sick                              2.0        NaN\n",
       "I cant sleep                                          2.0        NaN\n",
       "is doing homework                                     2.0        NaN\n",
       "with you. Your jst gonna make me sadder if you go     2.0        NaN\n",
       "Ok I REALLY need to go to bed and stop playing ...    2.0        NaN\n",
       "is seriously freakin out over next week!!!!!!! ...    2.0        NaN\n",
       "is poorly sick                                        2.0        NaN\n",
       "has learned a new juggle(/bounce?) for christie...    2.0        NaN\n",
       "@ddlovato AJ RAFAEL (AWESOME MUSICIAN, FAMOUS O...    2.0        NaN\n",
       "Good morning world!                                   2.0        NaN\n",
       "...                                                   ...        ...\n",
       "Life is too short..                                   1.0        NaN\n",
       "so happy to be back in prison                         1.0        NaN\n",
       "missed his train as the geniuses at the station...    1.0        NaN\n",
       "Oh no! look at the time! It's time for me to be...    1.0        NaN\n",
       "http://twitpic.com/6fwfw - Rip-My brothers Hair...    1.0        NaN\n",
       "@lazylightning1 LOL! Didn't settle. It is a pad...    1.0        NaN\n",
       "Is up feeding Kaylee                                  1.0        NaN\n",
       "such a bad headache. wheres katie?  tell her i'...    1.0        NaN\n",
       "@Rocmoney I knowww                                    1.0        NaN\n",
       "Its rained for a full week                            1.0        NaN\n",
       "I am trying to figure out m.slandr.net... Twitt...    1.0        NaN\n",
       "it's rainy, yeah                                      1.0        NaN\n",
       "Watching Matilda                                      1.0        NaN\n",
       "@Deejaywilliams Pic for me didn't work.               1.0        NaN\n",
       "@IAMtheCOMMODORE andrew, you need to get a blog...    1.0        NaN\n",
       "@xTerlasifiQue Ahaha, thanks!  It's on Wednesda...    1.0        NaN\n",
       "I met her, but I didn't get a picture  but i di...    1.0        NaN\n",
       "Our God Country To DEFEND - In tthaaaaaaaaaa &q...    1.0        NaN\n",
       "my blackberry is being lame. no twitpics  I jus...    1.0        NaN\n",
       "@lautner_taylor i love you sooooooo much!! y r ...    1.0        NaN\n",
       "i hate sky+ for not filming all of princess pro...    1.0        NaN\n",
       "Hello my 1,000th tweet                                1.0        NaN\n",
       "working  looking forward to weekend.                  1.0        NaN\n",
       "OH MY GGGOD,SO BORINGG THATS IT WATCHING STUPID...    1.0        NaN\n",
       "@DCMA_Collective a speaker at my church yesterd...    1.0        NaN\n",
       "Just got back to grammys. Mums on her way to En...    1.0        NaN\n",
       "@elainechan98 hahaha my parents éº»éº»åœ°æ¬£è³ž...    1.0        NaN\n",
       "@katekinners YES! I really thank you for the li...    1.0        NaN\n",
       "4                                                     NaN    16010.0\n",
       "0                                                     NaN    15990.0\n",
       "\n",
       "[31943 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.apply(pd.value_counts) # Check and count all duplicated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=training_df.drop_duplicates(keep='last') # Remove duplicated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is seriously freakin out over next week!!!!!!! cant wait till friday  n Im FREE!!!!!! oh dear ive got a dance exam 2 worry about 2!  xxx</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thunderstorm</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has learned a new juggle(/bounce?) for christie  yeyee.. 5 wins nadagdag sakin and 2 loss  http://plurk.com/p/z2fhe</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@asinkujobear lol what..i was thirsty!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pray your day was great and trust that lives were changed... Now time to chill with my Wife  peace</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@NikkiLynette What the hek is the real meaning behind stalkerbait anyway? There are only a posts about it. My number is public anyway</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i just washed my car and of course it rained</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok so this just about kills it 2mph &amp;amp; 72miles 2 go 2 catch the 6pm ferry</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello ... wow  it's sunny day   luv it</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@oukego Thomas Dolby of course!  &amp;quot;Close but no CIgar&amp;quot; is the name of the song.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Rell8182 Definitely</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@amandametheny Me too...</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Quiggmate: Thank you sooo mmuchh x you have made my day  x!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@tommcfly Hey Tom, can I sugest something to you, please? btw, i miss you and the guys here in Brazil!  be back soon! xx</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@omgitsashton I hope you feel better soon</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodnight..gotta read this book for class 2moro</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Rfunkz:eyaa..just blehh. oyasumi</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So annoyed because someone gave my last pieces of good cheese to the dog!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@hellparade I'm so jealous haha I've been dying to play it! But I can't because my computer is crap</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@sarebearxx8 okay get duff &amp;amp;  geof to do it.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@stevenhorner and your right, teach me not to jump to conclusions - I hadnt looked at the URL  good news though! thanks for noticing</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinner and then going to sleep .... Harold  ....... bye peoples</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doesnt want to go to work</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@drops_of_dmb will do! Haven't had much luck in my search though</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@NickkkJonasss You were amazing at Wembley last night! Well done  Cant wait for november now! xxx</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thinks my bro-in-law is not a good husband. tsk tsk tsk...  http://plurk.com/p/11lzzr</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@5DollarDinners You may want to monitor your content more closely. Once you go full feed, people have easier access to steal</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i just got makeup and I had to get the palest colour...how depressing</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doesnt feel well at all</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ReelJPMorgan I'm tellin u. I'm pretty mean in the kitchen lolol they're yummy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is up feeding Kaylee</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such a bad headache. wheres katie?  tell her i'm stuck in tallatrashy without her. h8 maiiii lyf3.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Rocmoney I knowww</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Its rained for a full week</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I am trying to figure out m.slandr.net... Twitter Mobile does not work on my phone (bummer)</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it's rainy, yeah</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Watching Matilda</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Deejaywilliams Pic for me didn't work.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@IAMtheCOMMODORE andrew, you need to get a blog   haha i love you</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@xTerlasifiQue Ahaha, thanks!  It's on Wednesday though. &amp;lt;3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I met her, but I didn't get a picture  but i did get a high five</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Our God Country To DEFEND - In tthaaaaaaaaaa &amp;quot;AIR FORCE&amp;quot;  http://bit.ly/ARayu   LOOK UP Moooooooo</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my blackberry is being lame. no twitpics  I just finished lunch now off to see my lady Suzy.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@lautner_taylor i love you sooooooo much!! y r u playin jake</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i hate sky+ for not filming all of princess protection program. what a bitch!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hello my 1,000th tweet</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working  looking forward to weekend.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH MY GGGOD,SO BORINGG THATS IT WATCHING STUPIDS THINGS. HAHAHAHAHAHA  .&amp;quot;</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@DCMA_Collective a speaker at my church yesterday was wearing a DCMA hoodie.. thought that was cool</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Just got back to grammys. Mums on her way to England and Dillon is on his way home  miss them both.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@elainechan98 hahaha my parents éº»éº»åœ°æ¬£è³ž my cookings... coz i only know how to cook è¥¿å¼?é‡Ž</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://twitpic.com/7yqd6 - Finally got my camera! I don't know what to do with any of this.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@BabyKayCee I've known people who have managed to get it around level 30ish  so it's definitely possible!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back to the &amp;quot;The O.C.&amp;quot; marathon. Lovin' Seth Cohen</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ericssan thx! Well I can do the water part but only get 3-4hrs of sleep per night</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Zoexander Very very very very cool.  http://www.inbflat.net/ More details? How it was made? Please tell</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so i guess blink tickets in vegas are sold out... but their considering doing a second show here</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@katekinners YES! I really thank you for the link!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15956.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet  Sentiment\n",
       "is seriously freakin out over next week!!!!!!! ...    2.0        NaN\n",
       "thunderstorm                                          2.0        NaN\n",
       "has learned a new juggle(/bounce?) for christie...    2.0        NaN\n",
       "@asinkujobear lol what..i was thirsty!                1.0        NaN\n",
       "Pray your day was great and trust that lives we...    1.0        NaN\n",
       "@NikkiLynette What the hek is the real meaning ...    1.0        NaN\n",
       "i just washed my car and of course it rained          1.0        NaN\n",
       "Ok so this just about kills it 2mph &amp; 72mil...    1.0        NaN\n",
       "Hello ... wow  it's sunny day   luv it                1.0        NaN\n",
       "@oukego Thomas Dolby of course!  &quot;Close bu...    1.0        NaN\n",
       "@Rell8182 Definitely                                  1.0        NaN\n",
       "@amandametheny Me too...                              1.0        NaN\n",
       "@Quiggmate: Thank you sooo mmuchh x you have ma...    1.0        NaN\n",
       "@tommcfly Hey Tom, can I sugest something to yo...    1.0        NaN\n",
       "@omgitsashton I hope you feel better soon             1.0        NaN\n",
       "goodnight..gotta read this book for class 2moro       1.0        NaN\n",
       "@Rfunkz:eyaa..just blehh. oyasumi                     1.0        NaN\n",
       "So annoyed because someone gave my last pieces ...    1.0        NaN\n",
       "@hellparade I'm so jealous haha I've been dying...    1.0        NaN\n",
       "@sarebearxx8 okay get duff &amp;  geof to do it.      1.0        NaN\n",
       "@stevenhorner and your right, teach me not to j...    1.0        NaN\n",
       "Dinner and then going to sleep .... Harold  ......    1.0        NaN\n",
       "Doesnt want to go to work                             1.0        NaN\n",
       "@drops_of_dmb will do! Haven't had much luck in...    1.0        NaN\n",
       "@NickkkJonasss You were amazing at Wembley last...    1.0        NaN\n",
       "thinks my bro-in-law is not a good husband. tsk...    1.0        NaN\n",
       "@5DollarDinners You may want to monitor your co...    1.0        NaN\n",
       "i just got makeup and I had to get the palest c...    1.0        NaN\n",
       "Doesnt feel well at all                               1.0        NaN\n",
       "@ReelJPMorgan I'm tellin u. I'm pretty mean in ...    1.0        NaN\n",
       "...                                                   ...        ...\n",
       "Is up feeding Kaylee                                  1.0        NaN\n",
       "such a bad headache. wheres katie?  tell her i'...    1.0        NaN\n",
       "@Rocmoney I knowww                                    1.0        NaN\n",
       "Its rained for a full week                            1.0        NaN\n",
       "I am trying to figure out m.slandr.net... Twitt...    1.0        NaN\n",
       "it's rainy, yeah                                      1.0        NaN\n",
       "Watching Matilda                                      1.0        NaN\n",
       "@Deejaywilliams Pic for me didn't work.               1.0        NaN\n",
       "@IAMtheCOMMODORE andrew, you need to get a blog...    1.0        NaN\n",
       "@xTerlasifiQue Ahaha, thanks!  It's on Wednesda...    1.0        NaN\n",
       "I met her, but I didn't get a picture  but i di...    1.0        NaN\n",
       "Our God Country To DEFEND - In tthaaaaaaaaaa &q...    1.0        NaN\n",
       "my blackberry is being lame. no twitpics  I jus...    1.0        NaN\n",
       "@lautner_taylor i love you sooooooo much!! y r ...    1.0        NaN\n",
       "i hate sky+ for not filming all of princess pro...    1.0        NaN\n",
       "Hello my 1,000th tweet                                1.0        NaN\n",
       "working  looking forward to weekend.                  1.0        NaN\n",
       "OH MY GGGOD,SO BORINGG THATS IT WATCHING STUPID...    1.0        NaN\n",
       "@DCMA_Collective a speaker at my church yesterd...    1.0        NaN\n",
       "Just got back to grammys. Mums on her way to En...    1.0        NaN\n",
       "@elainechan98 hahaha my parents éº»éº»åœ°æ¬£è³ž...    1.0        NaN\n",
       "http://twitpic.com/7yqd6 - Finally got my camer...    1.0        NaN\n",
       "@BabyKayCee I've known people who have managed ...    1.0        NaN\n",
       "back to the &quot;The O.C.&quot; marathon. Lovi...    1.0        NaN\n",
       "@ericssan thx! Well I can do the water part but...    1.0        NaN\n",
       "@Zoexander Very very very very cool.  http://ww...    1.0        NaN\n",
       "so i guess blink tickets in vegas are sold out....    1.0        NaN\n",
       "@katekinners YES! I really thank you for the li...    1.0        NaN\n",
       "4                                                     NaN    15988.0\n",
       "0                                                     NaN    15956.0\n",
       "\n",
       "[31943 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.apply(pd.value_counts) # Check and count all duplicated tweets\n",
    "# We found there are \"4\" and \"0\" for the same tweet content, which will cause confusion. \n",
    "# We consider those as \"confusion\" tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        31944\n",
       "Sentiment    31944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Reduce tweets from 32000 to 31944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all \"confusion\" tweets in column \"Tweet\"\n",
    "training_df['Tweet'] = training_df['Tweet'].drop_duplicates(keep=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        31938\n",
       "Sentiment    31944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all line of \"confusion\" tweets\n",
    "training_df=training_df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        31938\n",
       "Sentiment    31938\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Reduce tweets from 31944 to 31938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Pool size changed, may indicate binary incompatibility. Expected 48 from C header, got 64 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\tblakeley\\appdata\\local\\programs\\python\\python36\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: cymem.cymem.Address size changed, may indicate binary incompatibility. Expected 24 from C header, got 40 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# python -m spacy download en\n",
    "\n",
    "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df1=training_df #Create training_df['Tweet']1 as a back-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowercase the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['Tweet']=training_df['Tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey &amp; wa...\n",
       "1                    @atif089 cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5    @prettyhoneydip iight lol ; i got u when i tal...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7    @jessicagottlieb  prime example why it doesn't...\n",
       "8                        @bettie_mcfly you know, why? \n",
       "9    @mcrmuffin d i got your update on my phone!! y...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove @Word and \"#Word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTags(s):\n",
    "    s = re.sub(\"@[a-zA-Z0-9_]+\",\" \", s) #remove the @<the word>\n",
    "    s = re.sub(\"#[a-zA-Z0-9_]+\",\" \", s) #remove the #<the word>\n",
    "    return s\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey &amp; wa...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing HTML and HTTP Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(strip_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removehttp(http):\n",
    "    http = re.sub(r\"http\\S+\", \"\", http) #remove the http://<the word>\n",
    "    return http\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removehttp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_accented_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6             thinks she has run up a a300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6             thinks she has run up a a300 phone bill \n",
       "7       prime example why it does not really pay to...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert spaces between special characters to isolate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertspace(inspace):\n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    inspace = special_char_pattern.sub(\" \\\\1 \", inspace)\n",
    "    return inspace\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(insertspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNumbers(n):\n",
    "    n = re.sub(\"1[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"2[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"3[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"4[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"5[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"6[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"7[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"8[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"9[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"[0-9]\",\" \", n) \n",
    "    return n\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeNumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    text = re.sub('[^a-zA-Z0-9\\s+]', '', text)\n",
    "    text = re.sub('[+]', '', text)\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite drinkin earl grey  watchin ...\n",
       "1                             cool that would be nice \n",
       "2           i hate lynz       sorry i just had to s...\n",
       "3                          is awake bored and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol  i got u when i talk   him   im no...\n",
       "6               thinks she has run up a a  phone bill \n",
       "7       prime example why it does not really pay to...\n",
       "8                                        you know why \n",
       "9      d i got your update on my phone     yus   wa...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    have relaxin nite drinkin earl grey   watchin ...\n",
       "1                              cool that would be nice\n",
       "2            i hate lynz        sorry i just have t...\n",
       "3                           be awake bored and annoyed\n",
       "4                     song of the day    lacey awesome\n",
       "5       iight lol   i get u when i talk    him    i...\n",
       "6               think she have run up a a   phone bill\n",
       "7        prime example why it do not really pay to ...\n",
       "8                                         you know why\n",
       "9       d i get your update on my phone      yus   ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    have relaxin nite drinkin earl grey watchin a ...\n",
       "1                              cool that would be nice\n",
       "2              i hate lynz sorri i just have to say it\n",
       "3                               be awak bore and annoy\n",
       "4                         song of the day lacey awesom\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "#for word in nlp(training_df['Tweet'][1]):\n",
    "    #print(word)\n",
    "    \n",
    "def stem_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    " \n",
    "    stem_tokens = [ps.stem(token) for token in tokens]\n",
    "    filtered_text = ' '.join(stem_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(stem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    have relaxin nite drinkin earl grey   watchin ...\n",
       "1                              cool that would be nice\n",
       "2            i hate lynz        sorry i just have t...\n",
       "3                           be awake bored and annoyed\n",
       "4                     song of the day    lacey awesome\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    relaxin nite drinkin earl grey watchin cool sh...\n",
       "1                                      cool would nice\n",
       "2                                  hate lynz sorry say\n",
       "3                                  awake bored annoyed\n",
       "4                               song day lacey awesome\n",
       "5                        iight lol get u talk not home\n",
       "6                                 think run phone bill\n",
       "7    prime example not really pay autofollow irresp...\n",
       "8                                                 know\n",
       "9                  get update phone yus wat matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeline(line):\n",
    "    line = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',line)\n",
    "    return line\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removewhite(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removewhite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    relaxin nite drinkin earl grey watchin cool sh...\n",
       "1                                      cool would nice\n",
       "2                                  hate lynz sorry say\n",
       "3                                  awake bored annoyed\n",
       "4                               song day lacey awesome\n",
       "5                        iight lol get u talk not home\n",
       "6                                 think run phone bill\n",
       "7    prime example not really pay autofollow irresp...\n",
       "8                                                 know\n",
       "9                  get update phone yus wat matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relaxin nite drinkin earl grey watchin cool sh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool would nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate lynz sorry say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake bored annoyed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song day lacey awesome</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iight lol get u talk not home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>think run phone bill</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prime example not really pay autofollow irresp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>know</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>get update phone yus wat matter tho</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  relaxin nite drinkin earl grey watchin cool sh...          4\n",
       "1                                    cool would nice          4\n",
       "2                                hate lynz sorry say          0\n",
       "3                                awake bored annoyed          0\n",
       "4                             song day lacey awesome          4\n",
       "5                      iight lol get u talk not home          0\n",
       "6                               think run phone bill          0\n",
       "7  prime example not really pay autofollow irresp...          0\n",
       "8                                               know          4\n",
       "9                get update phone yus wat matter tho          0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31938"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        False\n",
       "Sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_csv('D:\\\\Education\\\\York U\\\\ML 1010\\\\Group Project\\\\Dataset\\\\training_cleaned.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
