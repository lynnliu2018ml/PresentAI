{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72 <br>AND Annie's \"Text Normalization Demo.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('D:\\\\Education\\\\York U\\\\ML 1010\\\\Group Project\\\\Dataset\\\\training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        32000\n",
       "Sentiment    32000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>havin relaxin nite, drinkin earl grey &amp;amp; wa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@atif089 cool that would be nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... i HATE lyn-z... sorry i just had to say it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is awake, bored, and annoyed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song of the day  http://tinyurl.com/cpkjrm lac...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  havin relaxin nite, drinkin earl grey &amp; wa...          4\n",
       "1                  @atif089 cool that would be nice           4\n",
       "2  ... i HATE lyn-z... sorry i just had to say it...          0\n",
       "3                      is awake, bored, and annoyed           0\n",
       "4  song of the day  http://tinyurl.com/cpkjrm lac...          4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head(5) # \"4\" represents \"positive\", \"0\" represents \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isPlayer Has Died! Sorry</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Morning</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My friends made me join twitter.. so here i am  hows everyones day so far?</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back to work</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@workformeonline I didn't understand that   Try commands like 'Buy 30 #tag' or 'Sell 30 #tag'</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So bored</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My tummy hurts</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with you. Your jst gonna make me sadder if you go</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rain rain go away</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I cant sleep</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just woke up</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good morning</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relaxing</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headache</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning everyone</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my head hurts</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning world!</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ok I REALLY need to go to bed and stop playing around with Twitter adding new friends!! Hello all you new people</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I think I'm getting sick</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>So tired</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has learned a new juggle(/bounce?) for christie  yeyee.. 5 wins nadagdag sakin and 2 loss  http://plurk.com/p/z2fhe</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Going to work</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not feeling well</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ddlovato AJ RAFAEL (AWESOME MUSICIAN, FAMOUS ON YOUTUBE) COVERED YOUR SONG, DON'T FORGET. PLEASE WATCH IT  IT'S GOOD! http://bit.ly/vFWAs</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off to work</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is poorly sick</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last day of school.</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is doing homework</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>getting ready for work</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@hideawayxx wow, that really is a coincidence :O i despise the orthodonist; my teeth always feel so sore afterwards. i know how you feel</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@midnightevent - i hate u! lady gaga followed you, hmmmph!  jk</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't wait till examss are overr... then partyy timee.  i hope i get 90% n above on my math examm. or else this studyingg is a wastee.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about to go to work. been waiting to long to give these gift certificates</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@_natearchibald I'm Great!  Its Good 2 Hear That!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@JoelMadden nice one!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...wait, your phone misses me? YOU don't miss me?  dumb hoe.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@aliciacaballero miserable. you guys are going without me?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night world. See you in the morning. I can't wait.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone has broken... laptop has broken... and the bus left as I ran to catch it - and I was standing by the door!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@MOARorange Agh I mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@thomasfiss you do suck at interviews but we still love you!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has to get up really early to say goodbye to one of his best friends.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@CaptainKazz yeah I guess so  it would be so much fun if you were in it though</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@LaurenMuchko So awesome that you love to teach...such a rewarding feeling</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@vrikis Better than work, work, 10 minutes for lunch, work, work, work? Actually it might be. I don't work very hard</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jlipschultz - No worries. @JesseHachey - In search of a new picture too. A one that has a more corporate look and setting</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Heads</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jaeboogiesmalls I think i'm falling in love with you!!  xxx #iloveyou</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yayyyyy I still don't understand this</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 down 3 to go and it's going to get worse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so sorry for me not being able to tweet... im just to damn lazy... okay i voted for the first time ever!!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i had pancakes for breakfast...wow that was a while ago...i miss him so much...  i get to see him and his haircut 2maro</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired so hard to make an website but i can't ugh</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*sadface* Lost another follower.. Watching MTV MA tonight.. Totally have the house to myself for the night! Woohoo!!!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ninacox No  I saw that documentary you linked and I thought of that. I'm sorry.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sixpence none the Richer is a Christian band for the most part -- and they r0ck! too bad they've disbanded</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ivettiso thanks much, Ivette! appreciate your time  What are the dates of the marathon?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15990.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet  Sentiment\n",
       "isPlayer Has Died! Sorry                              6.0        NaN\n",
       "Good morning                                          5.0        NaN\n",
       "Good Morning                                          3.0        NaN\n",
       "My friends made me join twitter.. so here i am ...    3.0        NaN\n",
       "back to work                                          3.0        NaN\n",
       "@workformeonline I didn't understand that   Try...    3.0        NaN\n",
       "So bored                                              3.0        NaN\n",
       "My tummy hurts                                        3.0        NaN\n",
       "with you. Your jst gonna make me sadder if you go     2.0        NaN\n",
       "rain rain go away                                     2.0        NaN\n",
       "I cant sleep                                          2.0        NaN\n",
       "just woke up                                          2.0        NaN\n",
       "good morning                                          2.0        NaN\n",
       "relaxing                                              2.0        NaN\n",
       "Headache                                              2.0        NaN\n",
       "Good morning everyone                                 2.0        NaN\n",
       "my head hurts                                         2.0        NaN\n",
       "Good morning world!                                   2.0        NaN\n",
       "Ok I REALLY need to go to bed and stop playing ...    2.0        NaN\n",
       "I think I'm getting sick                              2.0        NaN\n",
       "So tired                                              2.0        NaN\n",
       "has learned a new juggle(/bounce?) for christie...    2.0        NaN\n",
       "Going to work                                         2.0        NaN\n",
       "Not feeling well                                      2.0        NaN\n",
       "@ddlovato AJ RAFAEL (AWESOME MUSICIAN, FAMOUS O...    2.0        NaN\n",
       "off to work                                           2.0        NaN\n",
       "is poorly sick                                        2.0        NaN\n",
       "last day of school.                                   2.0        NaN\n",
       "is doing homework                                     2.0        NaN\n",
       "getting ready for work                                2.0        NaN\n",
       "...                                                   ...        ...\n",
       "@hideawayxx wow, that really is a coincidence :...    1.0        NaN\n",
       "@midnightevent - i hate u! lady gaga followed y...    1.0        NaN\n",
       "can't wait till examss are overr... then partyy...    1.0        NaN\n",
       "about to go to work. been waiting to long to gi...    1.0        NaN\n",
       "@_natearchibald I'm Great!  Its Good 2 Hear That!     1.0        NaN\n",
       "@JoelMadden nice one!                                 1.0        NaN\n",
       "...wait, your phone misses me? YOU don't miss m...    1.0        NaN\n",
       "@aliciacaballero miserable. you guys are going ...    1.0        NaN\n",
       "Night world. See you in the morning. I can't wa...    1.0        NaN\n",
       "phone has broken... laptop has broken... and th...    1.0        NaN\n",
       "@MOARorange Agh I mean                                1.0        NaN\n",
       "@thomasfiss you do suck at interviews but we st...    1.0        NaN\n",
       "has to get up really early to say goodbye to on...    1.0        NaN\n",
       "@CaptainKazz yeah I guess so  it would be so mu...    1.0        NaN\n",
       "@LaurenMuchko So awesome that you love to teach...    1.0        NaN\n",
       "@vrikis Better than work, work, 10 minutes for ...    1.0        NaN\n",
       "@jlipschultz - No worries. @JesseHachey - In se...    1.0        NaN\n",
       "Talking Heads                                         1.0        NaN\n",
       "@jaeboogiesmalls I think i'm falling in love wi...    1.0        NaN\n",
       "Yayyyyy I still don't understand this                 1.0        NaN\n",
       "2 down 3 to go and it's going to get worse            1.0        NaN\n",
       "so sorry for me not being able to tweet... im j...    1.0        NaN\n",
       "i had pancakes for breakfast...wow that was a w...    1.0        NaN\n",
       "tired so hard to make an website but i can't ugh      1.0        NaN\n",
       "*sadface* Lost another follower.. Watching MTV ...    1.0        NaN\n",
       "@ninacox No  I saw that documentary you linked ...    1.0        NaN\n",
       "Sixpence none the Richer is a Christian band fo...    1.0        NaN\n",
       "@ivettiso thanks much, Ivette! appreciate your ...    1.0        NaN\n",
       "4                                                     NaN    16010.0\n",
       "0                                                     NaN    15990.0\n",
       "\n",
       "[31943 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.apply(pd.value_counts) # Check and count all duplicated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df=training_df.drop_duplicates(keep='last') # Remove duplicated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thunderstorm</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is seriously freakin out over next week!!!!!!! cant wait till friday  n Im FREE!!!!!! oh dear ive got a dance exam 2 worry about 2!  xxx</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has learned a new juggle(/bounce?) for christie  yeyee.. 5 wins nadagdag sakin and 2 loss  http://plurk.com/p/z2fhe</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@leonwolf wow - who knew peonies were so interesting?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@Meriffic @JacobDrake Wednesday might work for me. Unless Ben comes home from hospital that day</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@topclasswoo dont worry .. i will .</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wooo  great party at iris'. &amp;amp; unbanned tomorrow at 3:33pm DD yessss. WAITING FOR THAT DAMNED MOMENT!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Last night a BJ saved my life. @Brieisyummie</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good morning everyone! Going to the beach with my mum and sis  http://bit.ly/Ej1fk   Remember sunscreen!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I dont get twitter</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pussycat Dolls are performing tonight @ Burswood Dome  Sad I won't be going.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morningggggg; tired  [getting ready for school]</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Race today!! Just finished writing it</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@shemah hehe okay Shem, but I'll try to chop..  I'm doing my MM now..</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@mileycyrus i miss my big bro  hes in japan right now playing rugby http://twitpic.com/6muah</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jerz_r1der that sucks so bad!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Also: Holy crap, the house of @lediva and @usernamenumber is being evicted!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@CaitEggers I don't know if you just changed your background or I never noticed but I like it  and I like that it matches my old one!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@pleasurep they leaked under a LONGGGGGG time ago  .. sorry to be the bearer of bad news... i still clicked the &amp;quot;sneak peak&amp;quot; tho .</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@pleatedkhakis I'm lost... I haven't seen the movie yet...</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@catherinegee It was really moving, Rick was genuinely moved! Where did you stand - we were right by the stage for DL.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the gloomy weather made me sleepy but I have a lot to clean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>About an half a hour im going to school untill a half pas 3.  Now im on my own laptop and doing my hair. Soo.. Kisskiss.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sexy thing in Eska`s music test  / at work</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jasmine_nia fyewwwhhh... yes. she is.   so, what happened in school when i was absent.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@skdev too bad mate, not getting SS here  that's the case with both cable networks i have</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Things I learn last nite. Gay guys got some serious game. I wanna be a gay dude in nyc. I can't wait till Hawaii</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@olalalaa Twitter always works... I actually quite like it! though it's not as time consuming as Facebook</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Just had my Fuji S9500 returned from servicing came back worst that before I sent it</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>On Facebook? Just published Ooffoo's fan page - please join  http://bit.ly/ZRQdJ #green #eco</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@aliciacaballero miserable. you guys are going without me?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Night world. See you in the morning. I can't wait.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phone has broken... laptop has broken... and the bus left as I ran to catch it - and I was standing by the door!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@MOARorange Agh I mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@thomasfiss you do suck at interviews but we still love you!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has to get up really early to say goodbye to one of his best friends.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...you'd think my cheechee's were fake with as much money as I have to put in to support them!!!  I KNOW I KNOW, TMI!!!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@CaptainKazz yeah I guess so  it would be so much fun if you were in it though</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@LaurenMuchko So awesome that you love to teach...such a rewarding feeling</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@vrikis Better than work, work, 10 minutes for lunch, work, work, work? Actually it might be. I don't work very hard</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jlipschultz - No worries. @JesseHachey - In search of a new picture too. A one that has a more corporate look and setting</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Talking Heads</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jaeboogiesmalls I think i'm falling in love with you!!  xxx #iloveyou</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yayyyyy I still don't understand this</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 down 3 to go and it's going to get worse</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>so sorry for me not being able to tweet... im just to damn lazy... okay i voted for the first time ever!!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i had pancakes for breakfast...wow that was a while ago...i miss him so much...  i get to see him and his haircut 2maro</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tired so hard to make an website but i can't ugh</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*sadface* Lost another follower.. Watching MTV MA tonight.. Totally have the house to myself for the night! Woohoo!!!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ninacox No  I saw that documentary you linked and I thought of that. I'm sorry.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sixpence none the Richer is a Christian band for the most part -- and they r0ck! too bad they've disbanded</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doing that double gym thing again today with some yoga too</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kris rocks BECAUSE he rocks with God!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Back from the gym. I'm getting sick</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@tomlowth 1 room half done. I hate skirting boards and ceilings so much it gives me energy!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The highlight of my night!!!! Awwwweeee teddy  http://mypict.me/2Phl</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@maxweels I want to go this year!!! I love Ibiza.</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@ivettiso thanks much, Ivette! appreciate your time  What are the dates of the marathon?</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15956.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Tweet  Sentiment\n",
       "thunderstorm                                          2.0        NaN\n",
       "is seriously freakin out over next week!!!!!!! ...    2.0        NaN\n",
       "has learned a new juggle(/bounce?) for christie...    2.0        NaN\n",
       "@leonwolf wow - who knew peonies were so intere...    1.0        NaN\n",
       "@Meriffic @JacobDrake Wednesday might work for ...    1.0        NaN\n",
       "@topclasswoo dont worry .. i will .                   1.0        NaN\n",
       "wooo  great party at iris'. &amp; unbanned tomo...    1.0        NaN\n",
       "Last night a BJ saved my life. @Brieisyummie          1.0        NaN\n",
       "Good morning everyone! Going to the beach with ...    1.0        NaN\n",
       "I dont get twitter                                    1.0        NaN\n",
       "Pussycat Dolls are performing tonight @ Burswoo...    1.0        NaN\n",
       "morningggggg; tired  [getting ready for school]       1.0        NaN\n",
       "Great Race today!! Just finished writing it           1.0        NaN\n",
       "@shemah hehe okay Shem, but I'll try to chop.. ...    1.0        NaN\n",
       "@mileycyrus i miss my big bro  hes in japan rig...    1.0        NaN\n",
       "@jerz_r1der that sucks so bad!                        1.0        NaN\n",
       "Also: Holy crap, the house of @lediva and @user...    1.0        NaN\n",
       "@CaitEggers I don't know if you just changed yo...    1.0        NaN\n",
       "@pleasurep they leaked under a LONGGGGGG time a...    1.0        NaN\n",
       "@pleatedkhakis I'm lost... I haven't seen the m...    1.0        NaN\n",
       "@catherinegee It was really moving, Rick was ge...    1.0        NaN\n",
       "the gloomy weather made me sleepy but I have a ...    1.0        NaN\n",
       "About an half a hour im going to school untill ...    1.0        NaN\n",
       "Sexy thing in Eska`s music test  / at work            1.0        NaN\n",
       "@jasmine_nia fyewwwhhh... yes. she is.   so, wh...    1.0        NaN\n",
       "@skdev too bad mate, not getting SS here  that'...    1.0        NaN\n",
       "Things I learn last nite. Gay guys got some ser...    1.0        NaN\n",
       "@olalalaa Twitter always works... I actually qu...    1.0        NaN\n",
       "Just had my Fuji S9500 returned from servicing ...    1.0        NaN\n",
       "On Facebook? Just published Ooffoo's fan page -...    1.0        NaN\n",
       "...                                                   ...        ...\n",
       "@aliciacaballero miserable. you guys are going ...    1.0        NaN\n",
       "Night world. See you in the morning. I can't wa...    1.0        NaN\n",
       "phone has broken... laptop has broken... and th...    1.0        NaN\n",
       "@MOARorange Agh I mean                                1.0        NaN\n",
       "@thomasfiss you do suck at interviews but we st...    1.0        NaN\n",
       "has to get up really early to say goodbye to on...    1.0        NaN\n",
       "...you'd think my cheechee's were fake with as ...    1.0        NaN\n",
       "@CaptainKazz yeah I guess so  it would be so mu...    1.0        NaN\n",
       "@LaurenMuchko So awesome that you love to teach...    1.0        NaN\n",
       "@vrikis Better than work, work, 10 minutes for ...    1.0        NaN\n",
       "@jlipschultz - No worries. @JesseHachey - In se...    1.0        NaN\n",
       "Talking Heads                                         1.0        NaN\n",
       "@jaeboogiesmalls I think i'm falling in love wi...    1.0        NaN\n",
       "Yayyyyy I still don't understand this                 1.0        NaN\n",
       "2 down 3 to go and it's going to get worse            1.0        NaN\n",
       "so sorry for me not being able to tweet... im j...    1.0        NaN\n",
       "i had pancakes for breakfast...wow that was a w...    1.0        NaN\n",
       "tired so hard to make an website but i can't ugh      1.0        NaN\n",
       "*sadface* Lost another follower.. Watching MTV ...    1.0        NaN\n",
       "@ninacox No  I saw that documentary you linked ...    1.0        NaN\n",
       "Sixpence none the Richer is a Christian band fo...    1.0        NaN\n",
       "doing that double gym thing again today with so...    1.0        NaN\n",
       "Kris rocks BECAUSE he rocks with God!                 1.0        NaN\n",
       "Back from the gym. I'm getting sick                   1.0        NaN\n",
       "@tomlowth 1 room half done. I hate skirting boa...    1.0        NaN\n",
       "The highlight of my night!!!! Awwwweeee teddy  ...    1.0        NaN\n",
       "@maxweels I want to go this year!!! I love Ibiza.     1.0        NaN\n",
       "@ivettiso thanks much, Ivette! appreciate your ...    1.0        NaN\n",
       "4                                                     NaN    15988.0\n",
       "0                                                     NaN    15956.0\n",
       "\n",
       "[31943 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.apply(pd.value_counts) # Check and count all duplicated tweets\n",
    "# We found there are \"4\" and \"0\" for the same tweet content, which will cause confusion. \n",
    "# We consider those as \"confusion\" tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        31944\n",
       "Sentiment    31944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Reduce tweets from 32000 to 31944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all \"confusion\" tweets in column \"Tweet\"\n",
    "training_df['Tweet'] = training_df['Tweet'].drop_duplicates(keep=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        31938\n",
       "Sentiment    31944\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all line of \"confusion\" tweets\n",
    "training_df=training_df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        31938\n",
       "Sentiment    31938\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.count() # Reduce tweets from 31944 to 31938"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning - Import necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from contractions import CONTRACTION_MAP\n",
    "import unicodedata\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "# python -m spacy download en\n",
    "\n",
    "nlp = spacy.load('en', parse=True, tag=True, entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df1=training_df #Create training_df['Tweet']1 as a back-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowercase the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df['Tweet']=training_df['Tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey &amp; wa...\n",
       "1                    @atif089 cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5    @prettyhoneydip iight lol ; i got u when i tal...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7    @jessicagottlieb  prime example why it doesn't...\n",
       "8                        @bettie_mcfly you know, why? \n",
       "9    @mcrmuffin d i got your update on my phone!! y...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove @Word and \"#Word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeTags(s):\n",
    "    s = re.sub(\"@[a-zA-Z0-9_]+\",\" \", s) #remove the @<the word>\n",
    "    s = re.sub(\"#[a-zA-Z0-9_]+\",\" \", s) #remove the #<the word>\n",
    "    return s\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey &amp; wa...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing HTML and HTTP Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(strip_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4    song of the day  http://tinyurl.com/cpkjrm lac...\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removehttp(http):\n",
    "    http = re.sub(r\"http\\S+\", \"\", http) #remove the http://<the word>\n",
    "    return http\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removehttp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6            thinks she has run up a â£300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_accented_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6             thinks she has run up a a300 phone bill \n",
       "7       prime example why it doesn't really pay to ...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite, drinkin earl grey & watchi...\n",
       "1                             cool that would be nice \n",
       "2    ... i hate lyn-z... sorry i just had to say it...\n",
       "3                        is awake, bored, and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol ; i got u when i talk 2 him. im no...\n",
       "6             thinks she has run up a a300 phone bill \n",
       "7       prime example why it does not really pay to...\n",
       "8                                      you know, why? \n",
       "9      d i got your update on my phone!! yus! wats ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert spaces between special characters to isolate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertspace(inspace):\n",
    "    special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "    inspace = special_char_pattern.sub(\" \\\\1 \", inspace)\n",
    "    return inspace\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(insertspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNumbers(n):\n",
    "    n = re.sub(\"1[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"2[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"3[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"4[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"5[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"6[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"7[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"8[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"9[a-zA-Z0-9_]+\",\" \", n) \n",
    "    n = re.sub(\"[0-9]\",\" \", n) \n",
    "    return n\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeNumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    text = re.sub('[^a-zA-Z0-9\\s+]', '', text)\n",
    "    text = re.sub('[+]', '', text)\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    havin relaxin nite drinkin earl grey  watchin ...\n",
       "1                             cool that would be nice \n",
       "2           i hate lynz       sorry i just had to s...\n",
       "3                          is awake bored and annoyed \n",
       "4                     song of the day   laceys awesome\n",
       "5      iight lol  i got u when i talk   him   im no...\n",
       "6               thinks she has run up a a  phone bill \n",
       "7       prime example why it does not really pay to...\n",
       "8                                        you know why \n",
       "9      d i got your update on my phone     yus   wa...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    have relaxin nite drinkin earl grey   watchin ...\n",
       "1                              cool that would be nice\n",
       "2            i hate lynz        sorry i just have t...\n",
       "3                           be awake bored and annoyed\n",
       "4                     song of the day    lacey awesome\n",
       "5       iight lol   i get u when i talk    him    i...\n",
       "6               think she have run up a a   phone bill\n",
       "7        prime example why it do not really pay to ...\n",
       "8                                         you know why\n",
       "9       d i get your update on my phone      yus   ...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    relaxin nite drinkin earl grey watchin cool sh...\n",
       "1                                      cool would nice\n",
       "2                                  hate lynz sorry say\n",
       "3                                  awake bored annoyed\n",
       "4                               song day lacey awesome\n",
       "5                        iight lol get u talk not home\n",
       "6                                 think run phone bill\n",
       "7    prime example not really pay autofollow irresp...\n",
       "8                                                 know\n",
       "9                  get update phone yus wat matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeline(line):\n",
    "    line = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',line)\n",
    "    return line\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removewhite(line):\n",
    "    line = re.sub(' +', ' ', line)\n",
    "    return line\n",
    "\n",
    "training_df['Tweet']=training_df['Tweet'].apply(removewhite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    relaxin nite drinkin earl grey watchin cool sh...\n",
       "1                                      cool would nice\n",
       "2                                  hate lynz sorry say\n",
       "3                                  awake bored annoyed\n",
       "4                               song day lacey awesome\n",
       "5                        iight lol get u talk not home\n",
       "6                                 think run phone bill\n",
       "7    prime example not really pay autofollow irresp...\n",
       "8                                                 know\n",
       "9                  get update phone yus wat matter tho\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relaxin nite drinkin earl grey watchin cool sh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cool would nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate lynz sorry say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake bored annoyed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>song day lacey awesome</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iight lol get u talk not home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>think run phone bill</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prime example not really pay autofollow irresp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>know</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>get update phone yus wat matter tho</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0  relaxin nite drinkin earl grey watchin cool sh...          4\n",
       "1                                    cool would nice          4\n",
       "2                                hate lynz sorry say          0\n",
       "3                                awake bored annoyed          0\n",
       "4                             song day lacey awesome          4\n",
       "5                      iight lol get u talk not home          0\n",
       "6                               think run phone bill          0\n",
       "7  prime example not really pay autofollow irresp...          0\n",
       "8                                               know          4\n",
       "9                get update phone yus wat matter tho          0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31938"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df['Tweet'].count() # Check number of non-NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet        False\n",
       "Sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.to_csv('D:\\\\Education\\\\York U\\\\ML 1010\\\\Group Project\\\\Dataset\\\\training_cleaned.csv',encoding='utf-8',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
